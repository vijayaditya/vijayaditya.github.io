<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0036)http://www.clsp.jhu.edu/people/vijay -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

<title></title>
<meta name="keywords" content="">
<meta name="description" content="">
<link rel="stylesheet" href="./index_files/screen.css" type="text/css" media="screen, projection">
<link rel="stylesheet" href="./index_files/people.css" type="text/css" media="screen, projection">
<link rel="stylesheet" href="./index_files/print.css" type="text/css" media="print">
<!--[if lte IE 8]>
<link rel="stylesheet"
    href="/styles/ie.css" type="text/css" media="screen, projection" />
<![endif]-->
<style>[href^="http://www.google.com/aclk?"],
[href^="http://www.linkbucks.com/referral/"],
#header + #content > #left > #rlblock_left,
#content > #right > .dose > .dosesingle,
#content > #center > .dose > .dosesingle
{display:none !important;}</style></head>

<body data-feedly-mini="yes">
	<div id="container" class="container">
		<div id="contact-info" class="span-10">
						<img src="./index_files/91_person-original.jpg" width="200" alt="Vijayaditya Peddinti" class="profile-photo">
			<br>
						<h3><strong><span style="font-size: 16px;"><a href="http://www.clsp.jhu.edu/people/vijay#aboutme">About me</a><br></span></strong><strong><span style="font-size: 16px;"><a href="http://www.clsp.jhu.edu/people/vijay#publication">Publications</a><br></span></strong><strong><span style="font-size: 16px;"><a href="http://www.clsp.jhu.edu/people/vijay#experience">Experience</a><br></span></strong><strong><span style="font-size: 16px;"><a href="http://www.clsp.jhu.edu/people/vijay#projects">Projects</a><br></span></strong><strong><span style="font-size: 16px;"><a href="http://www.clsp.jhu.edu/people/vijay#academics">Academics</a><br></span></strong><strong><span style="font-size: 16px;"><a href="http://goo.gl/CEQHrX">Resume</a></span></strong></h3>
<p><strong><span style="font-size: 18px;"><a href="http://www.clsp.jhu.edu/people/vijay#toolkits"><br></a></span></strong></p>
<address><span style="font-size: 16px;"><strong><span style="text-decoration: underline;"><span style="font-family: mceinline;"><span style="font-family: mceinline;">Contact Info:<br><br></span></span></span></strong><span style="font-family: mceinline;">vijay [dot] p [at] jhu [dot] edu<br></span></span></address><address><span style="font-size: 16px;"><span style="font-family: mceinline;">Hackerman 323,<br></span><span style="font-family: mceinline;"><br></span><span style="font-family: mceinline;"><span style="font-family: mceinline;">3400 North Charles Street,<br><br></span></span><span style="font-family: mceinline;"><span style="font-family: mceinline;">Baltimore, MD - 21218</span></span></span></address>
<p><span style="font-size: 16px;"><br></span></p>
<h1><span style="font-size: 18px;"><br></span><a href="http://www.clsp.jhu.edu/about-clsp" target="_blank"><span style="font-size: 18px;"><img title="logo" src="./index_files/clsp.gif" alt="clsp logo" width="147" height="159"></span></a></h1>		</div>
		<div class="span-35 prepend-top-2">
			<div id="content">
				<h1>Vijayaditya Peddinti</h1>
								<p><a name="aboutme"></a></p>
<h3>About me</h3>
<p><span style="text-align: justify; color: #222222; font-size: 14px;">I am a fourth year PhD student in the Electrical and Computer engineering department at Johns Hopkins University. I work in the</span><a style="text-align: justify; font-size: 14px;" href="http://www.clsp.jhu.edu/"> Center for Language and Speech Processing</a> on acoustic models for speech recognition, with Dan Povey and Sanjeev Khudanpur. I was previously working with Hynek Hermansky.</p>
<p><span style="text-align: justify; color: #222222; font-size: 14px;">I previously worked in </span><a style="text-align: justify; font-size: 14px;" href="http://speech.iiit.ac.in/">Speech and Vision Lab</a><span style="text-align: justify; color: #222222; font-size: 14px;"> at IIIT-Hyd with </span><a style="text-align: justify; font-size: 14px;" href="https://sites.google.com/site/kishoreprahallad/">Kishore Prahallad</a><span style="text-align: justify; color: #222222; font-size: 14px;">, on efficient back-off strategies for quality speech synthesis, for my Masters (by research)</span></p>
<p><strong>Research Interests:</strong> Speech Recognition, Machine Learning</p>
<hr>
<p><a name="publication"></a></p>
<h3>Publications</h3>
<ol>
<li><span style="font-weight: 700;">Vijayaditya Peddinti</span>, Daniel Povey and Sanjeev Khudanpur<br>A time delay neural network architecture for efficient modeling of long temporal contexts<br>in Proceedings of Interspeech 2015, <em>Germany</em></li>
<li><span style="font-weight: 700;">Vijayaditya Peddinti</span>, Guoguo Chen, Daniel Povey and Sanjeev Khudanpur<br>Reverberation robust acoustic modeling using i-vectors with time delay neural networks<br>in Proceedings of Interspeech 2015,Â&nbsp;<em>Germany</em></li>
<li><span style="font-weight: 700;">Tom Ko,</span><span style="font-weight: 700;"> </span><span style="font-weight: 700;">Vijayaditya Peddinti</span>, Daniel Povey and Sanjeev Khudanpur<br>Audio Augmentation for Speech Recognition<br>in Proceedings of Interspeech 2015,Â&nbsp;<em>Germany</em></li>
<li>Tara Sainath, <strong>Vijayaditya Peddinti</strong>, Brian Kingsbury, Petr Fousek, Bhuvana Ramabhadran and David Nahamoo<br>Deep Scattering Spectra with Deep Neural Networks for LVCSR Tasks<br>in Proceedings of Interspeech 2014, <em>Singapore</em></li>
<li>Thomas Schatz, <strong>Vijayaditya Peddinti</strong>, Xuan-Nga Cao, Francis Bach, Hynek Hermansky and Emmanuel Dupoux<br>Evaluating speech features with the Minimal-Pair ABX task (II): Resistance to noise<br>in Proceedings of Interspeech 2014, <em>Singapore</em></li>
<li><strong>Vijayaditya Peddinti</strong>, Tara Sainath, Shay Maymon, Bhuvana Ramabhadran, David Nahamoo, Vaibhava Goel<br>Deep Scattering Spectrum with Deep Neural Networks, <br>In proceedings of ICASSP 2014, <em>Florence</em></li>
<li>Thomas Schatz, <strong>Vijayaditya Peddinti</strong>, Francis Bach, Aren Jansen, Hynek Hermansky and Emmanuel Dupoux<br>Evaluating speech features with the Minimal-Pair ABX task: Analysis of the classical MFC/PLP pipeline<br>in Proceedings of INTERSPEECH 2013, <em>Lyon</em></li>
<li><strong>Vijayaditya Peddinti </strong>and Hynek Hermansky<br>Filter-bank optimization for frequency domain linear prediction<br>in Proceedings of ICASSP 2013, <em>Vancouver</em></li>
<li>Hynek Hermansky, Ehsan Variani and <strong>Vijayaditya Peddinti</strong><br>Mean temporal distance : Predicting ASR error from temporal properties of speech signal<br>in proceedings of ICASSP 2013, <em>Vancouver</em></li>
<li>Aren Jansen,<em>et al,</em><br>A summary of the 2012 JHU CLSP workshop on zero resource speech technologies and models of early language acquisition<br>in proceedings of ICASSP 2013,<em> Vancouver</em></li>
<li> <strong>Vijayaditya Peddinti </strong>and Kishore Prahallad.<br>Significance of epenthesis for Text-To-Speech synthesis in Telugu<br> In Proceedings of ICASSP, 2011, <em>Prague</em></li>
<li> <strong>Vijayaditya Peddinti</strong> and Kishore Prahallad.<br>Exploiting Phone-class specific Landmarks for Refinement of Segment Boundaries in TTS Databases<br>In Proceedings of INTERSPEECH, 2011, <em>Florence</em></li>
<li>Hema A. Murthy,..,<strong> Vijayaditya Peddinti </strong>and Kishore Prahallad.<br>Building Unit Selection Speech Synthesizers in Indian Languages: An Initiative by and Indian Consortium<br>In Proceedings of Oriental COCOSDA, 2010,<em>Kathmandu, Nepal</em></li>
<li>Veera Raghavendra Elluru,<strong> Vijayaditya Peddinti </strong>and<strong></strong>Kishore Prahallad.<br>Speech Synthesis using Artifical Neural Networks<br>In Proceedings of National Conference on Communications (NCC), 2010, <em>Chennai, India</em></li>
</ol>
<h1>
<hr>
</h1>
<p><a name="experience"></a></p>
<h3>Experience</h3>
<ul>
<li><span style="font-weight: 700;">Research Intern, Microsoft Research, Mentor: Mike SeltzerÂ&nbsp;</span>September 2014 - December 2014</li>
<li><strong>Research Intern, IBM T.J. Watson Research Center, Mentor: Tara SainathÂ&nbsp;</strong>May 2013 - August 2013</li>
<li><strong>Research Assistant, JHU</strong>, September 2011 - Current</li>
<li><strong>Teaching Assistant, JHU</strong>,;<br>Course: Processing of Audio and Visual Signals (Instructor: Prof. Hynek Hermansky)<br>Course: Speech and Audio processing by humans and machiens (Instructor: Prof. Hynek Hermansky)</li>
<li><strong>Analytics Intern, I-Labs 24/7 Customer , Bangalore</strong>, January 2011 - July 2011<br>Part of text and data mining team. Developed a prototype for Event detection in Twitter, Facebook, Forum and Customer Care chat data.</li>
<li><strong>Research Assistant, IIIT-Hyderabad, India</strong>, Dec 2008 - Dec 2010<br>Worked on the <em>Indian Language TTS (Ministry of Commn. and Info. Tech., India)</em> and <em>Indian Language Data Collection (LDC-IL) </em>projects</li>
<li><strong>Technical Associate, TechMahindra Ltd., </strong>Jul 2007 - July 2008</li>
</ul>
<hr>
<p><a name="projects"></a></p>
<h3>Projects</h3>
<p><em>Past Projects:</em></p>
<ul>
<li><strong>Robust Automatic Transcription of Speech (RATS)<em>:</em></strong><br> DARPA project </li>
<li><strong>Indian Language TTS ,<br></strong><em>Funded By Ministry of Commn. &amp; Info. Tech., India (MCIT)</em><br>Involved in the development of a text-to-speech (TTS) synthesizer for Telugu as part of the Indian Language TTS Consortium. Developed an algorithm for automatic segmentation of audio databases (published in Interspeech, 2011) and designed a back-off strategy for missing units (published in ICASSP,2011), implementation syllable based synthesizer in the Festival framework.</li>
<li><strong>Indian Language Data Collection</strong><br><em>Funded by Lang. Data Consortium Indian Languages (LDC-IL)<br></em>Worked on Automatic generation of phonetic alignments of audio data with erroneous transcripts for speech data in Telugu as part of Indian Language Data Collection project for LDC-IL for the collection of 500 hours of speech data each for Telugu, Kannada and English languages.</li>
<li><strong>Temporal Event Detection in Social Media Streams</strong><br>At I-labs, 24/7 Customer<br>Developed an algorithm for event detection in volume time series created from multiple data streams like microblogs (like Twitter), social networks (like Facebook) and Chats (from customer service centers).</li>
</ul>
<hr>
<p><a name="academics"></a></p>
<h3>Academics</h3>
<ul>
<br>
<li><strong>Johns Hopkins University, </strong>Maryland, US<br>PhD in Electrical and Computer Engineering, 2011 - Present;</li>
<li><strong>International Institute of Information Technology</strong>, Hyderabad, India<br> Master of Science (by Research) in Computer Science, 2011</li>
<li><strong>Dhirubhai Ambani Institute of Information and Communication Technology</strong>, Gandhinagar, India<br>Bachelor of Technology in Information and Communication Technology, 2007</li>
</ul>
<hr>
<p><a name="toolkits"></a></p>
<h3 style="text-align: start;"><br></h3>
<ul style="text-align: start;">
</ul>				<div id="publications" class="prepend-top-1">
				<p align="right"><a href="http://www.clsp.jhu.edu/_dataproviders/bibtex_export.php?author=91" title="Export Vijayaditya Peddinti&#39;s Publications to BibTeX"><img src="./index_files/bibtex.png" alt=""></a>&nbsp;&nbsp;<a class="expand cursor"></a></p>
				<h3>2015</h3><a id="peddinti2015multisplice"></a><div id="pub-1048" class="publications"><p>A time delay neural network architecture for efficient modeling of long temporal contexts<br><a href="http://www.clsp.jhu.edu/people/vijay/" target="_blank">Vijayaditya Peddinti</a>, <a href="http://www.danielpovey.com/" target="_blank">Daniel Povey</a> and <a href="http://www.clsp.jhu.edu/~sanjeev/" target="_blank">Sanjeev Khudanpur</a><br><em>Submitted to Interspeech – 2015</em></p><p align="right"><a id="abstract-1048" class="cursor" rel="toggle" title="A time delay neural network architecture for efficient modeling of long temporal contexts">[abstract]</a> <a id="bib-1048" class="cursor" rel="toggle" title="A time delay neural network architecture for efficient modeling of long temporal contexts">[bib]</a></p><div id="abstract-1048" class="hide abstract"><h3>Abstract</h3>Recurrent neural network architectures have been shown to efficiently model long term temporal dependencies between acoustic events. However the training time of recurrent networks is higher than feedforward networks due to the sequential nature of the learning algorithm. In this paper we propose a time delay neural network architecture which models long term temporal dependencies with training times comparable to standard feed-forward DNNs. The network uses sub-sampling to reduce computation during training. On the Switchboard task we show a relative improvement of 6% over the baseline DNN model. We present results on several LVCSR tasks with training data ranging from 3 to 1800 hours to show the effectiveness of the TDNN architecture in learning wider temporal dependencies in both small and large data scenarios.</div><div id="bib-1048" class="hide bib align-left">@{peddinti2015multisplice,<br>
	author = {Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev}, <br>
	title = {A time delay neural network architecture for efficient modeling of long temporal contexts}, <br>
	booktitle = {Submitted to Interspeech}<br>
 }</div></div><a id="peddinti2015reverb"></a><div id="pub-1049" class="publications alt"><p>Reverberation robust acoustic modeling using with time delay neural networks<br><a href="http://www.clsp.jhu.edu/people/vijay/" target="_blank">Vijayaditya Peddinti</a>, <a href="http://www.clsp.jhu.edu/~guoguo/" target="_blank">Guoguo Chen</a>, <a href="http://www.danielpovey.com/" target="_blank">Daniel Povey</a> and <a href="http://www.clsp.jhu.edu/~sanjeev/" target="_blank">Sanjeev Khudanpur</a><br><em>Submitted to Interspeech 2015 – 2015</em></p><p align="right"><a id="abstract-1049" class="cursor" rel="toggle" title="Reverberation robust acoustic modeling using with time delay neural networks">[abstract]</a> <a id="bib-1049" class="cursor" rel="toggle" title="Reverberation robust acoustic modeling using with time delay neural networks">[bib]</a></p><div id="abstract-1049" class="hide abstract"><h3>Abstract</h3>In reverberant environments there are long term interactions be- tween speech and corrupting sources. In this paper a time de- lay neural network (TDNN) architecture, capable of learning long term temporal relationships and translation invariant representations, is used for reverberation robust acoustic model- ing. Further, iVectors are used as an input to the neural network to perform instantaneous speaker and environment adaptation, providing 10% relative improvement in word error rate. By sub- sampling the outputs at TDNN layers across time steps, training time is reduced. Using a parallel training algorithm we show that the TDNN can be trained on âˆ¼ 5500 hours of speech data in 3 days using up to 32 GPUs. The TDNN is shown to provide results competitive with state of the art systems in the IARPA ASpIRE challenge, with 27.7% WER on the dev test set.</div><div id="bib-1049" class="hide bib align-left">@{peddinti2015reverb,<br>
	author = {Peddinti, Vijayaditya and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev}, <br>
	title = {Reverberation robust acoustic modeling using with time delay neural networks}, <br>
	booktitle = {Submitted to Interspeech 2015}<br>
 }</div></div><a id="ko2014augmentation"></a><div id="pub-1050" class="publications"><p>Audio Augmentation for Speech Recognition<br>Tom Ko, <a href="http://www.clsp.jhu.edu/people/vijay/" target="_blank">Vijayaditya Peddinti</a>, <a href="http://www.danielpovey.com/" target="_blank">Daniel Povey</a> and <a href="http://www.clsp.jhu.edu/~sanjeev/" target="_blank">Sanjeev Khudanpur</a><br><em>Submitted to Interspeech 2015 – 2015</em></p><p align="right"><a id="abstract-1050" class="cursor" rel="toggle" title="Audio Augmentation for Speech Recognition">[abstract]</a> <a id="bib-1050" class="cursor" rel="toggle" title="Audio Augmentation for Speech Recognition">[bib]</a></p><div id="abstract-1050" class="hide abstract"><h3>Abstract</h3>Data augmentation is a common strategy adopted to increase the quantity of training data, avoid overfitting and improve robustness of the models. In this paper, we investigate audio-level speech augmentation methods which directly process the raw signal. The method we particularly recommend is to change the speed of the audio signal, producing 3 versions of the original signal with speed factors of 0.9, 1.0 and 1.1. The proposed technique has a low implementation cost, making it easy to adopt. We present results on 4 different LVCSR tasks with training data ranging from 100 hours to 1000 hours, to examine the effectiveness of audio augmentation in a variety of data scenarios. An average relative improvement of 4.3% was observed across the 4 tasks.</div><div id="bib-1050" class="hide bib align-left">@{ko2014augmentation,<br>
	author = {Tom Ko and Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev}, <br>
	title = {Audio Augmentation for Speech Recognition}, <br>
	booktitle = {Submitted to Interspeech 2015}<br>
 }</div></div><p align="right"><small><a href="http://www.clsp.jhu.edu/people/vijay#">Back to Top</a></small></p><h3>2014</h3><a id="schatz-peddinti-cao-bach-hermansky-dupoux:is2014c"></a><div id="pub-988" class="publications alt"><p>Evaluating speech features with the Minimal-Pair ABX task (II): Resistance to noise<br>Thomas Schatz, <a href="http://www.clsp.jhu.edu/people/vijay/" target="_blank">Vijayaditya Peddinti</a>, <a href="" target="_blank">Yuan Cao</a>, Francis Bach, <a href="http://www.clsp.jhu.edu/~hynek/" target="_blank">Hynek Hermansky</a> and Emmanuel Dupoux<br><em>Proc. of INTERSPEECH – 2014</em></p><p align="right"><a id="bib-988" class="cursor" rel="toggle" title="Evaluating speech features with the Minimal-Pair ABX task (II): Resistance to noise">[bib]</a></p><div id="bib-988" class="hide bib align-left">@inproceedings{schatz-peddinti-cao-bach-hermansky-dupoux:is2014c,<br>
	author = {Thomas Schatz and Peddinti, Vijayaditya and Cao, Yuan and Francis Bach and Hermansky, Hynek and Emmanuel Dupoux}, <br>
	title = {Evaluating speech features with the Minimal-Pair ABX task (II): Resistance to noise}, <br>
	booktitle = {Proc. of INTERSPEECH}<br>
 }</div></div><p align="right"><small><a href="http://www.clsp.jhu.edu/people/vijay#">Back to Top</a></small></p><h3>2013</h3><a id="schatz-peddinti-bach-jansen-hermansky-dupoux:is2013"></a><div id="pub-998" class="publications"><p>Evaluating speech features with the Minimal-Pair ABX task: Analysis of the classical MFC/PLP pipeline<br>Thomas Schatz, <a href="http://www.clsp.jhu.edu/people/vijay/" target="_blank">Vijayaditya Peddinti</a>, Francis Bach, <a href="http://www.clsp.jhu.edu/~ajansen/" target="_blank">Aren Jansen</a>, <a href="http://www.clsp.jhu.edu/~hynek/" target="_blank">Hynek Hermansky</a> and Emmanuel Dupoux<br><em>Proc. INTERSPEECH – 2013</em></p><p align="right"><a id="bib-998" class="cursor" rel="toggle" title="Evaluating speech features with the Minimal-Pair ABX task: Analysis of the classical MFC/PLP pipeline">[bib]</a></p><div id="bib-998" class="hide bib align-left">@inproceedings{schatz-peddinti-bach-jansen-hermansky-dupoux:is2013,<br>
	author = {Thomas Schatz and Peddinti, Vijayaditya and Francis Bach and Jansen, Aren and Hermansky, Hynek and Emmanuel Dupoux}, <br>
	title = {Evaluating speech features with the Minimal-Pair ABX task: Analysis of the classical MFC/PLP pipeline}, <br>
	booktitle = {Proc. INTERSPEECH}<br>
 }</div></div><a id="jansen-dupoux-goldwater-johnson-khudanpur-church-feldman-hermansky-metze-rose-seltzer-clark-mcgraw-varadarajan-bennett-borschinger-chiu-dunbar-fourtassi-harwath-lee-levin-norouzain-peddinti-richardson-schatz-thomas:icassp2013"></a><div id="pub-1005" class="publications alt"><p>A Summary Of The 2012 JHU CLSP Workshop on Zero Resource Speech Technologies and Models of Early Language Acquisition<br><a href="http://www.clsp.jhu.edu/~ajansen/" target="_blank">Aren Jansen</a>, Emmanuel Dupoux, Sharon Goldwater, Mark Johnson, <a href="http://www.clsp.jhu.edu/~sanjeev/" target="_blank">Sanjeev Khudanpur</a>, <a href="http://www.clsp.jhu.edu/~kchurch/" target="_blank">Kenneth Church</a>, Naomi Feldman, <a href="http://www.clsp.jhu.edu/~hynek/" target="_blank">Hynek Hermansky</a>, Florian Metze, Richard Rose, Michael Seltzer, Pascal Clark, Ian Mcgraw, <a href="http://sites.google.com/site/balakrishnanvaradarajan/" target="_blank">Balakrishnan Varadarajan</a>, Erin Bennett, Benjamin Borschinger, Justin Chiu, Ewan Dunbar, Abdellah Fourtassi, David Harwath, Chia-Ying Lee, <a href="" target="_blank">Keith Levin</a>, Atta Norouzain, <a href="http://www.clsp.jhu.edu/people/vijay/" target="_blank">Vijayaditya Peddinti</a>, Rachael Richardson, Thomas Schatz and <a href="http://www.clsp.jhu.edu/~samuel/" target="_blank">Samuel Thomas</a><br><em>Proc. ICASSP – 2013</em></p><p align="right"><a id="bib-1005" class="cursor" rel="toggle" title="A Summary Of The 2012 JHU CLSP Workshop on Zero Resource Speech Technologies and Models of Early Language Acquisition">[bib]</a></p><div id="bib-1005" class="hide bib align-left">@inproceedings{jansen-dupoux-goldwater-johnson-khudanpur-church-feldman-hermansky-metze-rose-seltzer-clark-mcgraw-varadarajan-bennett-borschinger-chiu-dunbar-fourtassi-harwath-lee-levin-norouzain-peddinti-richardson-schatz-thomas:icassp2013,<br>
	author = {Jansen, Aren and Emmanuel Dupoux and Sharon Goldwater and Mark Johnson and Khudanpur, Sanjeev and Church, Kenneth and Naomi Feldman and Hermansky, Hynek and Florian Metze and Richard Rose and Michael Seltzer and Pascal Clark and Ian Mcgraw and Varadarajan, Balakrishnan and Erin Bennett and Benjamin Borschinger and Justin Chiu and Ewan Dunbar and Abdellah Fourtassi and David Harwath and Chia-Ying Lee and Levin, Keith and Atta Norouzain and Peddinti, Vijayaditya and Rachael Richardson and Thomas Schatz and Thomas, Samuel}, <br>
	title = {A Summary Of The 2012 JHU CLSP Workshop on Zero Resource Speech Technologies and Models of Early Language Acquisition}, <br>
	booktitle = {Proc. ICASSP}, <br>
	address = {Vancouver, Canada}<br>
 }</div></div><a id="hermansky-variani-peddinti:icassp2013"></a><div id="pub-1006" class="publications"><p>Mean Temporal Distance: Predicting ASR Error from Temporal Properties of Speech Signal<br><a href="http://www.clsp.jhu.edu/~hynek/" target="_blank">Hynek Hermansky</a>, <a href="http://www.clsp.jhu.edu/~variani/" target="_blank">Ehsan Variani</a> and <a href="http://www.clsp.jhu.edu/people/vijay/" target="_blank">Vijayaditya Peddinti</a><br><em>Proc. ICASSP – 2013</em></p><p align="right"><a id="bib-1006" class="cursor" rel="toggle" title="Mean Temporal Distance: Predicting ASR Error from Temporal Properties of Speech Signal">[bib]</a></p><div id="bib-1006" class="hide bib align-left">@inproceedings{hermansky-variani-peddinti:icassp2013,<br>
	author = {Hermansky, Hynek and Variani, Ehsan and Peddinti, Vijayaditya}, <br>
	title = {Mean Temporal Distance: Predicting ASR Error from Temporal Properties of Speech Signal}, <br>
	booktitle = {Proc. ICASSP}, <br>
	address = {Vancouver, Canada}<br>
 }</div></div><a id="peddinti-hermansky:icassp2013"></a><div id="pub-1007" class="publications alt"><p>Filter-Bank Optimization for Frequency Domain Linear Prediction<br><a href="http://www.clsp.jhu.edu/people/vijay/" target="_blank">Vijayaditya Peddinti</a> and <a href="http://www.clsp.jhu.edu/~hynek/" target="_blank">Hynek Hermansky</a><br><em>Proc. ICASSP – 2013</em></p><p align="right"><a id="bib-1007" class="cursor" rel="toggle" title="Filter-Bank Optimization for Frequency Domain Linear Prediction">[bib]</a></p><div id="bib-1007" class="hide bib align-left">@inproceedings{peddinti-hermansky:icassp2013,<br>
	author = {Peddinti, Vijayaditya and Hermansky, Hynek}, <br>
	title = {Filter-Bank Optimization for Frequency Domain Linear Prediction}, <br>
	booktitle = {Proc. ICASSP}, <br>
	address = {Vancouver, Canada}<br>
 }</div></div><p align="right"><small><a href="http://www.clsp.jhu.edu/people/vijay#">Back to Top</a></small></p>				</div>
			</div>
			<div id="footer">
				<p>© Vijayaditya Peddinti, 2015. All rights reserved.</p>
			</div>
		</div>
		<div class="clear"></div>
	</div>
	<script type="text/javascript" src="./index_files/jquery.min.js"></script>
	<script type="text/javascript">
		$('.publications:odd').addClass('alt');
		$('a.expand').bind('click', function () {
			$('div.abstract').toggle('blind');
			$(this).toggleClass('compress');
		});
		$('a.compress').bind('click', function () {
			$('div.abstract').toggle('blind');
			$(this).toggleClass('compress');
		});
		$("a[rel=toggle]").bind('click', function () {
			var id = $(this).attr('id');
			$('div#' + id).toggle('blind');
		});
	</script>

		<iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div><div id="feedly-mini" title="feedly Mini tookit"></div></body></html>