\documentclass[margin,line,pifont,palatino,courier]{res}


\usepackage{longtable}
\usepackage{pifont}
\usepackage[latin1] { inputenc}

%\topmargin .5in
%\oddsidemargin -.5in
%\evensidemargin -.5in
%\textwidth=6.0in
 \textheight=9.0in
%\itemsep=0in
%\parsep=0in
\usepackage{fancyhdr}
%\topmargin=0in
%\textheight=8.5in
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\fancyhf{}
%\cfoot{\thepage}
%\lfoot{\textit{\footnotesize Research Statement}}
\rfoot{{\footnotesize Curriculum Vitae, Vijayaditya Peddinti, \thepage}}


\newenvironment{list1}{
  \begin{list}{\ding{113}}{%
      \setlength{\itemsep}{0in}
      \setlength{\parsep}{0in} \setlength{\parskip}{0in}
      \setlength{\topsep}{0in} \setlength{\partopsep}{0in}
      \setlength{\leftmargin}{0.17in}}}{\end{list}}
\newenvironment{list2}{
  \begin{list}{$\bullet$}{%
      \setlength{\itemsep}{0in}
      \setlength{\parsep}{0in} \setlength{\parskip}{0in}
      \setlength{\topsep}{0in} \setlength{\partopsep}{0in}
      \setlength{\leftmargin}{0.2in}}}{\end{list}}

\begin{document}

\name{Vijayaditya Peddinti \vspace*{.1in}}

\begin{resume}

\section{\sc Contact Information}

\vspace{.05in}
\begin{tabular}{@{}p{2.75in}p{2in}}
Center for language and Speech Processing (CLSP) & (347)574-1561 \\
Electrical and Computer Eng. Department                        & \verb+vijay.p@jhu.edu+\\
Johns Hopkins University                  & \verb+http://www.clsp.jhu.edu/people/vijay+\\
3400 North Charles Street               & \\
Baltimore, Maryland 21218 USA               & \\
\end{tabular}

\section{\sc Research Interests}
Speech signal processing and Machine Learning with focus on Acoustic modeling for robust speech recognition
\section{\sc Education}

{\bf Whiting School of Engineering, Johns Hopkins University}\\
\vspace*{-.1in}
\begin{list1}
\item[] Ph.D.~Candidate, ECE (expected July 2016)

\begin{list2}
\vspace*{.05in}
\item Dissertation Topic:  Distortion stable sequence recognition using multi-rate neural networks
\item Advisor: Daniel Povey and Sanjeev Khudanpur
\end{list2}
\end{list1}

{\bf International Institute of Information Technology - Hyderabad}\\
\vspace*{-.1in}
\begin{list1}
\item[] M.S. by Research, CS, May 2011

\begin{list2}
\vspace*{.05in}
\item Dissertation Topic:  Synthesis of missing units in a Telugu text-to-speech system 
\item Advisor: Kishore Prahallad
\end{list2}
\end{list1}

{\bf Dhirubhai Ambani Inst. of Inf. and Comm. Technology (DAIICT)}\\
\vspace*{-.1in}
\begin{list1}
\item[] B.Tech.~in Information and Communication Technology, May 2007

\begin{list2}
\vspace*{.05in}
\item Topic: Note Histogram based hash function for Content Based Music Information Retrieval (CBMIR) 
\item Advisor: Vijaykumar Chakka
\end{list2}
\end{list1}

\section{\sc Achievements}
\begin{itemize}
\item Recipient of the Frederick Jelinek Fellowship 2015
\item Winner of the IARPA ASpIRE far field recognition challenge, 2015
\item Recipient of the best student paper award at Interspeech 2015
\end{itemize}


\section{\sc Publications}
\begin{enumerate}

\item \textbf{Vijayaditya Peddinti}, Guoguo Chen, Vimal Manohar, Tom Ko, Daniel Povey and Sanjeev Khudanpur,
\textit{JHU ASpIRE system: Robust LVCSR with TDNNs, iVector adaptation and RNN-LMs}, in Proceedings of ASRU 2015\\

\item \textbf{Vijayaditya Peddinti}, Daniel Povey, Sanjeev Khudanpur,
\textit{A time delay neural network architecture for efficient modeling of long temporal contexts}, in Proceedings of INTERSPEECH 2015\\
\textbf{Best paper award}

\item \textbf{Vijayaditya Peddinti}, Guoguo Chen, Daniel Povey, Sanjeev Khudanpur,
\textit{Reverberation robust acoustic modeling using i-vectors with time delay neural networks}, in Proceedings of INTERSPEECH 2015\\
\textbf{Winner of the IARPA ASpIRE far field recognition challenge}

\item Tom Ko, \textbf{Vijayaditya Peddinti}, Daniel Povey, Sanjeev Khudanpur,
\textit{Audio Augmentation for Speech Recognition}, in Proceedings of INTERSPEECH 2015

\item Tara Sainath, \textbf{Vijayaditya Peddinti}, Brian Kingsbury, Petr Fousek, Bhuvana Ramabhadran and David Nahamoo,
\textit{Deep Scattering Spectra with Deep Neural Networks for LVCSR Tasks}, in Proceedings of INTERSPEECH 2014

\item Thomas Schatz, \textbf{Vijayaditya Peddinti}, Xuan-Nga Cao, Francis Bach, Hynek Hermansky and Emmanuel Dupoux,
\textit{Evaluating speech features with the Minimal-Pair ABX task (II): Resistance to noise}, in Proceedings of INTERSPEECH 2014

\item \textbf{Vijayaditya Peddinti}, Tara Sainath, Shay Maymon, Bhuvana Ramabhadran, David Nahamoo, Vaibhava Goel,
\textit{Deep Scattering Spectrum with Deep Neural Networks}, in Proceedings of ICASSP 2014

\item Thomas Schatz, \textbf{Vijayaditya Peddinti}, Francis Bach, Aren Jansen, Hynek Hermansky and Emmanuel Dupoux,
\textit{Evaluating speech features with the Minimal-Pair ABX task: Analysis of the classical MFC/PLP pipeline}, in Proceedings of INTERSPEECH 2013, Lyon

\item \textbf{Vijayaditya Peddinti} and Hynek Hermansky,
\textit{Filter-bank optimization for frequency domain linear prediction}, in Proceedings of ICASSP 2013, Vancouver

\item Hynek Hermansky, Ehsan Variani and \textbf{Vijayaditya Peddinti},
\textit{Mean temporal distance: Predicting ASR error from temporal properties of speech signal}, in Proceedings of ICASSP 2013, Vancouver

\item Aren Jansen,et al, 
\textit{A summary of the 2012 JHU CLSP workshop on zero resource speech technologies and models of early language acquisition}, in Proceedings of ICASSP 2013, Vancouver


\item \textbf{Vijayaditya Peddinti} and Kishore Prahallad,
\textit{Significance of epenthesis for Text-To-Speech synthesis in Telugu}, in Proceedings of ICASSP, 2011, Prague

\item \textbf{Vijayaditya Peddinti} and Kishore Prahallad,
\textit{Exploiting Phone-class specific Landmarks for Refinement of Segment Boundaries in TTS Databases}, in Proceedings of INTERSPEECH, 2011, Florence

\item Hema A. Murthy,et al, 
\textit{Building Unit Selection Speech Synthesizers in Indian Languages: An Initiative by Indian Consortium}, In Proceedings of Oriental COCOSDA, 2010, Kathmandu, Nepal

\item Veera Raghavendra Elluru, \textbf{Vijayaditya Peddinti} and Kishore Prahallad.
\textit{Speech Synthesis using Artifical Neural Networks}, in Proceedings of National Conference on Communications (NCC), 2010, Chennai, India
\end{enumerate}
\section{\sc Research and Industrial Experience}

\begin{longtable}{@{}p{1.2in}p{3.8in}}

\textbf{July '15--Aug '15} & \textbf{Jelinek Summer Workshop on Speech and Language Technology} \\
& Member of the Far-field speech processing team \\
&\\

\textbf{Sep '14--Nov '14} & \textbf{Research Intern at Microsoft Research in Speech Recognition Group} \\
& Mentor : Mike Seltzer \\
&\\

\textbf{July '14--July '14} & \textbf{Fred Jelinek Memorial Workshop, Prague} \\
& Member of the Speech team working on ASR error prediction in mismatch conditions \\
&\\

\textbf{May '13--Aug '13} & \textbf{Research Intern at IBM T.J. Watson Research Center in Speech Transcription Technologies} \\
& Involved in the use of Deep Scattering Spectrum in acoustic modelling for speech recognition\\
& Mentor : Tara Sainath \\
&\\
\textbf{Aug '11--Present} & \textbf{Research Assistant at Center for Language and Speech Processing, Johns Hopkins University.} \\
&\textit{Robust Automatic Transcription of Speech (RATS):} Funded by DARPA \\
&Involved in the project on processing of noisy and degraded speech for speech activity detection, keyword spotting, language identification and speaker identification. Developed feature extraction techniques for noise robust acoustic modeling (published in ICASSP, 2013).\\
&\\
&\textit{Zero Resource Speech Technologies and Models of Early Language Acquisition}, Summer workshop CLSP\\
&Developed speaker invariant features for keyword spotting in zero resource scenarios (published in ICASSP, 2013).\\
&\\
\textbf{Jan '11--Jul '11} & \textbf{Analytics Intern at I-Labs, [24]7 Inc.} \\
&Involved in algorithm development for event detection in volume time series created from multiple data streams like microblogs (like Twitter), social networks (like Facebook) and Chats (from customer service centers).\\
&\\
\textbf{Dec '08--Dec '10 }& \textbf{Research Assistant at IIIT-Hyd at the Speech and Vision Lab} \\

&\textit{Indian Language TTS} ,
Funded By Ministry of Commn. \& Info. Tech., India (MCIT)\\
&Involved in the development of a text-to-speech (TTS) synthesizer for Telugu. Developed an algorithm for automatic segmentation of audio databases (published in Interspeech, 2011) and designed a back-off strategy for missing units (published in ICASSP,2011), implementation syllable based synthesizer in the Festival framework.\\
&\\
&\textit{Indian Language Data Collection} , 
Funded by Lang. Data Consortium of Indian Languages (LDC-IL)\\
&Worked on automatic generation of phonetic alignments of audio data with erroneous transcripts, for speech data in Telugu as part of project for the collection of speech data each in Telugu, Kannada and English languages.\\

&\\
\textbf{Jul '07--Jul '08} & \textbf{Technical Associate at Techmahindra Ltd.} \\
\end{longtable}

\section{\sc Teaching Experience}

\begin{tabular}{@{}p{0.4in}p{0.5in}p{4in}}
Spring & 2013 & Teaching Assistant, Speech and audio processing by humans and machines\\
\\
Fall & 2012,2013 & Teaching Assistant, Processing of audio and visual signals\\
\end{tabular}


\section{\sc Graduate Coursework}

\begin{tabular}{@{}p{2.3in}p{3in}}
\begin{list1}
\item Speech and audio processing by humans and machines
\item Information Extraction
\item Matrix Analysis
\item Random Signal Analysis
\item Machine Learning in Complex Domains


\end{list1}
&
\begin{list1}
\item Processing of audio and visual signals
\item Wavelets and Filter Banks
\item Computational Molecular Medicine (Techniques for Pattern Recognition in low data scenarios)
\item Optimization
\end{list1}

\end{tabular}


\section{\sc Programming}

\begin{tabular}{@{}p{0.8in}p{6in}}

Languages:& Python, C++, shell script, MATLAB\\
Toolkits: & KALDI, PyLearn2, Theano \\

\end{tabular}

\section{\sc Relevant \\ Skills}

\begin{tabular}{@{}p{0.8in}p{6in}}

Languages:& English, Hindi, Telugu\\

\end{tabular}




\section{\sc References}

Will be provided on request.

\end{resume}
\end{document}
